
# 问题分析与理解
## 本题难点:
1.  缺失数据几乎全部是整块丢失.

        预测的时候几乎除了时间,不能从中得到有价值的特征
2.  每块数据缺失的长度不一致.
        
        缺少数据如果只是缺少一行,和一下缺少1000行,这样的预测难道肯定是不一样的,得到的结果也会差别很大
3.  需要预测的有68个特征
        
        每个特征有不同的分布趋势,这样每个列肯定是不同的模型和参数,如果人为的逐一去搜索,工作量可想而知.
4.  如何构建和在线一致的本地测试集
        
        每个缺失块大小不一,每个列缺失的数据多少不一,如果使用随机Split很难模拟到接近的分布.
        
            
## 求解思路:
1. 难点1:
        
大量特征即使跨风机也具有很强相关性, 通过关联不同文件的数据构造特征, 下图就是挑选的有代表性的多列

![image](http://github.com/Flyfoxs/df_jf/raw/master/img/1.png)

![image](http://github.com/Flyfoxs/df_jf/raw/master/img/2.png)

![image](http://github.com/Flyfoxs/df_jf/raw/master/img/3.png)

2. 难点2:
            
            在模型中设置动态参数,根据缺失数据块的大小来分别构造Train数据,具体参数可以参考下面的模型设计
3. 难点3:
            
            在模型的设计中,把常见的回归,树模型都作为一个嵌套模型,通过参数控制.自动的寻找最优参数(模型)
4. 难点4:

- 建立缺失数据字典,对每一个连续的数据块和缺失块,存储起始地址.
- 在缺失块对应的数据块,前后都可以找到和缺失块一样大小的块来模拟缺失块,这样隐含参数也基本一致.

![image](http://github.com/Flyfoxs/df_jf/raw/master/img/9.png)
            
       

## 方案细节
下面3个模型的训练方法基本一致,就是内部嵌入各种模型,通过参数共享来避免过拟合. 3个模型的区别在于,最优参数的选择方法不一致.

1. 模型1:

         每一列,每一个缺失块单独预测,
         模型内部参数 
                - class_name: 线性回归,随机森林
                - col_name: 模型针对的列, var001, var002.... var068
                - drop_threshold: 当特征的缺失值大于 (1-drop_threshold) 丢失该特征
                - file_num: 从几个文件提取出相关特征
                - momenta_impact: 惯性影响的比例(前后都受影响). 如果设置0.1, 就是缺失块前后各10%直接填充,具体的填充值由momenta_col_length控制.
                - momenta_col_length: 统计指定范围的众数或者均值(前后都受影响). 如果是1,就是直接使用ffill, bfill
                - related_col_count: 指定获取多少个高相关的列来作为特征, 如果是0,就只从别的文件取相同的列作为特征. 
                - col_per: 对最终选取的特征,做最后一步过滤, 剔除相关性比较差的特征. 如果col_per = 0.9, 初步筛选特征有30个, 则只保留相关性最高的27个特征参与训练.
                - time_sn: 是否引入时间变量作为一个维度
                - window: 根据缺失数据块的大小,选择多少长度的数据参与训练. 如果window=1.5, 且缺失数据块长度为100, 则从缺失数据块前后各取150行参与训练.
                - n_estimators: 使用树模型时的参数
                - max_depth: 使用树模型时的参数
         模型超参:
                如果直接使用上面的参数对每一个缺失块进行预测,肯定很显然的会造成过拟合.所以使用了参数共享的办法.把类似的缺失块分为一组,每一组共享上面的参数.这样,这个分组方法就是本模型唯一的超参.
 
                分组方法有如下几种
                    根据缺失块长度使用pd.cut 分为多块
                    根据缺失块长度使用pd.qcut分为多块
                    根据缺失块的时间距离分块
                    或者根据长度和距离,综合考虑来分块
            
         最优参数的选择:
                针对训练的结果,在分组内部根据评价函数取平均值,选择分数最高的参数作为最终模型参数来预测test数据   
        
2. 模型2:
           
           在和队友融合时,虽然模型1已经在很多列中取得了较好成绩.但是经过分析发现,模型1有如下2个缺点:
           1)虽然参数共享一定程度,避免了过拟合,但是分组并不均匀,在组内数据较少时,还是会有较大过拟合.
           2)有充足的Train数据的情况下,没有使用交叉检验,数据存在浪费
           针对上面的缺点,模型2 对 模型1的最优参数选择进行了修改, 在缺失数据块的上部创建一个样本作为validate, 使用validate的分数来选择最优参数.
           修改后,通过在线测试,分数有很大提高,模型2可以在模型1已经收敛的情况下,寻找到更优参数
           
           
3. 模型3:

            虽然模型2已经取得了比较大的进步,但是他只使用了validate的分数来选择最有参数,对training数据的分数和结果造成了浪费.
            所以模型3使用了validate和training数据的总和来选取最优参数.
            

## 模型的优缺点:
- 优点:
            
            本地评分:不用依赖于有限的线上测评机会
            简单: 模型虽然引入了多个参数,但是超参只有一个,不需要人工对数据进行分析,极大的节省了人力   
            极大程度的避免了过拟合: 在比赛结束时,模型3还没有收敛到最优值,并且每次提交都能得到更好成绩
            模型融合:自然的嵌入了各种常见模型作为子模型,自动化的实现了模型选择与融合
- 缺点:
            
            计算量比较大,但是可以通过多种方法避免.
            1)迁移学习,在不同数据集上面学到的最好参数,换数据集后也许不是最优的,但是一定是较优的,基于这个参数展开搜索极大的节省空间.
            2)分布式计算,由于每一个缺失块都是单独预测,这样导致了可以十分容易的将计算分布到不同节点计算,并且节点之间没有通信的需求.
            


    
## 继续改进的空间:  
- 好几个参数没有展开搜索
- 只使用了线性回归
- 只使用了相关性来做特征选择
- 对大缺失块增加更多资源来训练,增加搜索空间
    
    
## 比赛经验总结和感想
    
    模型融合很重要:大家都知道打比赛要取得好成绩,一定要融合不同的模型. 
    其实人也是一个模型,一个人打比赛视野是受限的.当以团队的力量来完成一个事情的时候,这何尝不是一种模型融合.



## 代码结构
    
    ├── bin
    │   ├── main.sh 
    │   ├── predict.sh
    ├── cache 存放缓存数据
    ├── core
    │   ├── check.py 参数的生成及动态扩展
    │   ├── config.py 配置文件,密码,服务器地址
    │   ├── config_local.py 本地配置文件,不上传服务器,比如线程大小,缓存大小
    │   ├── db.py 读写DB的方法
    │   ├── feature.py 特征的准备
    │   ├── merge.py 逐块预测缺失数据, 然后合并到template文件
    │   ├── merge_multiple_file.py 用于和队友合并文件时使用
    │   ├── predict.py 训练模型相关
    ├── ddl
    │   ├── ddl 数据库的建表语句
    ├── imp  存放模型参数快照
    │   ├── lr_bin_9.h5
    │   ├── v3.h5
    ├── input 存放训练原始数据
    │   ├── 033
    │   │   └── 201807.csv
    │   ├── submit_example.csv
    │   └── template_submit_result.csv
    ├── notebook 存放jupyter 文件
    │   ├── hyx_code.ipynb
    │   ├── hyx_version_306.ipynb
    │   ├── merge_final_file.ipynb
    ├── output 存放模型的输出结果
    ├── requirements.txt






